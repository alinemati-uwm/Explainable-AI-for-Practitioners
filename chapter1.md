# What Is Explainable AI?

At Explainable AI’s core is the creation of explanations, or to create explainability for a model. Explainability is the concept that a model’s actions can be described in terms that are comprehensible to whoever is consuming the predictions of the ML model. This explainability serves a variety of purposes, from improving model quality to building confidence, and even providing a pathway for remediation when a prediction is not one you were expecting. As we have built increasingly complex models, we have discovered that a high-performing model is not sufficient to be acceptable in the real world. It is necessary that a prediction also has a reasonable explanation and, overall, the model behaves in the way its creators intended.

# Challenges in Explainability

In Explainable AI, there are several outstanding challenges:

- Demonstrating the semantic correctness of explanation techniques above and beyond the theoretical soundness of the underlying mathematics

- Combining different explanation techniques in an easy and safe way that enhances understanding rather than generating more confusion

- Building tools that allow consumers to easily explore, probe, and build richer explanations

- Generating explanations that are computationally efficient

- Building a strong framework for determining the robustness of explanation techniques